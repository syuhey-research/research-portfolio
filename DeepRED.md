# DeepRED: Rule Extraction from Deep Neural Networks

## 背景
近年、ディープニューラルネットワーク（DNN）は多くの分野で従来手法を凌駕する性能を示している。しかし、その高精度の裏で **「なぜその予測が出たのか」** という意思決定根拠はブラックボックス化されており、安全性が求められる医療、金融、自動運転などの分野では透明性が不可欠である【Loza IW19 Prague】。  
その解決策の一つが、ニューラルネットワークの振る舞いを **人間が理解できるルール（if–then規則）** に変換することである。

---

## ルール抽出のアプローチ
ニューラルネットワークからのルール抽出には主に3つの方法が存在する【Loza IW19 Prague】。

- **分解型**: ネットワーク構造や各ニューロンの重みを直接解析する方法  
- **教育型**: ネットワークをブラックボックスとみなし、入出力関係からルールを学習する方法  
- **折衷型**: 両者を組み合わせた方法  

---

## DeepREDとは
**DeepRED** は、Zilke, Loza Mencía, Janssen (TU Darmstadt) による、**ディープニューラルネットワークからルールを抽出する初の試み** である。  
従来の [**CRED (Continuous/discrete Rule Extractor via Decision tree induction)**](CRED.md) を拡張し、任意の層数を持つDNNに対応している。

- **CREDの特徴**: 1層の隠れ層のみを対象に、C4.5決定木を使ってルールを生成  
- **DeepREDの拡張**: DNNを層ごとに分解し、ニューロン単位でCREDを適用してルールを抽出  
- **位置づけ**: ニューロンの構造に基づく点では分解型、ニューロンの挙動を模倣する点では教育型のハイブリッド  

---

## 実験と結果
DeepREDは人工データセットやXOR問題などで検証されている。

- **artif-I データセット**: 複雑な比較ルールを含む場合、DeepREDはペダゴジカル手法よりも **コンパクトで理解しやすいルール** を抽出した。  
- **XOR問題**: 決定木では困難なパリティ関数も、DeepREDは >90% の忠実度（fidelity）でルール化に成功した。  
- **利点**: 複雑な隠れ概念を活用することで、シンプルかつ高精度なルール抽出が可能である。  
- **限界**: 単純な構造（artif-II）では、通常の決定木の方が理解しやすいルールを得られる場合もある。  

---

## 他手法との比較

| 手法 | アプローチ | 説明の単位 | 特徴 | 限界 |
|------|------------|------------|------|------|
| **LIME** | 擬似的なローカル線形モデルを学習 | 個別予測（インスタンスごと） | ・シンプルな線形モデルで局所説明を提供<br>・実装が容易 | ・局所的説明に依存（グローバルな理解は難しい）<br>・背景分布や摂動の仕方に結果が影響 |
| **SHAP** | Shapley値に基づく寄与度分析 | 個別予測（インスタンスごと） | ・理論的に厳密な特徴重要度を提供<br>・一貫性・局所精度の保証 | ・計算コストが高い<br>・寄与度の足し算のみでルール的説明は得られない |
| **Anchors** | 高精度なルール集合（if–then）によるローカル説明 | 個別予測（ローカルルール） | ・条件付きルールで直感的説明が可能<br>・「この条件が満たされれば予測は固定される」という保証 | ・ルールはインスタンス局所に限定<br>・ルールの適用範囲が狭いことも多い |
| **DeepRED** | ネットワークの層構造を分解しルール抽出 | モデル全体（グローバル） | ・ディープネットワークの**内部論理を層ごとに模倣**<br>・複雑な概念を単純なルールで表現可能<br>・全体的な透明性を提供 | ・ルール数が増えると可読性が低下<br>・単純な問題では決定木に劣る場合あり |

---

### ポイント
- **LIME・SHAP** は「局所的」説明 → ある入力に対して「どの特徴が効いたか」を明らかにする。  
- **Anchors** は「局所ルール」で説明 → 特定条件下での予測の安定性を示す。  
- **DeepRED** は「グローバルルール」抽出 → DNN全体の意思決定プロセスをルール集合で可視化できる。  

👉 LIMEやSHAPは「**その予測の理由**」を説明するのに適し、  
👉 DeepREDは「**モデル全体の論理**」を解釈するのに強い。  

---

## まとめ
- DeepREDは **ディープネットワークの内部表現を明示化** し、人間が読めるルールに変換する手法である。  
- 多くのケースで従来のブラックボックス型ルール抽出よりも **高い忠実度と理解しやすさ** を実現した。  
- 今後、医療・金融・自動運転などの安全性が重要な分野で、説明可能なAI（XAI）の基盤技術として期待される。  


## 参考文献
- Zilke, J. R., Loza Mencía, E., & Janssen, F. (2016).  
  *DeepRED – Rule Extraction from Deep Neural Networks.*  
  International Conference on Discovery Science (DS 2016).  

