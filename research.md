# 研究概要

## 背景（Why）
近年、深層学習や大規模機械学習モデルは高精度を達成している一方で、**意思決定の根拠がブラックボックス化**しており、医療・金融・産業など重要分野での活用に課題がある。  
従来のXAI技術（LIME, SHAP, Grad-CAMなど）は**個別予測の説明は得られる**ものの、複数ルールの組み合わせや全体最適化までは扱えない。

## 目的（What）
本研究の目的は、ブラックボックスモデルから抽出した**if-thenルール群の最適な組み合わせ**を構築し、  
モデルの予測根拠を**人間が理解しやすく、かつ性能も維持できる形**で表現すること。

## 手法（How）
1. ブラックボックスモデル（例: 深層学習モデル）から個別ルールを抽出  
   - 既存のルール抽出手法（DeepRED, TREPAN, RuleFitなど）を活用  

2. ルール群をノードとして**遺伝的ネットワークプログラミング（GNP）**で最適化  
   - ルールはノード、ルール間の論理的つながりはネットワークの枝として表現  
   - **なぜGNPを使うか**：
     - 単純なルール組み合わせだけでなく、**ノード間のつながり（ルールの依存関係や順序）も同時に最適化**できる  
     - ルール数が膨大でも、**進化的探索により指数的な組み合わせ計算を避けられる**  
     - 遺伝的操作（交叉・突然変異）で効率的に探索空間をサンプリングし、精度と説明可能性を両立  

3. 適応度関数として **予測精度＋説明容易性** を設定  
   - 精度を落とさずに、人間が理解しやすいネットワーク構造を評価  

4. 他のXAI手法（LIME, SHAP, Grad-CAM）と比較すると、  
   - 個別予測の説明だけでなく、**ルール全体の最適化＋依存関係の可視化**が可能


![フローチャート](images/method.png)

## 成果
- ルール最適化により、元モデルの精度を **95%維持**  
- 可視化されたルールネットワークにより、意思決定の論理が直感的に理解可能  
- [論文リンク](https://〜)  
- [スライドPDF](slides/research_presentation.pdf)

## 応用
- 医療診断モデル：AI予測の根拠を医師に提示  
- 金融審査モデル：決定理由の透明化による規制対応  
- 製造業予測システム：保守判断や異常検知の説明可能化

